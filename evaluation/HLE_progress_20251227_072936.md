# HLE Local Eval + Profiling 变更说明（vs `7eae53c`）

> 参考实现计划：`/workspace/.cursor/plans/hle_local_eval_script_44523c3d.plan.md`  
> 当前 staged 统计：**16 files changed，+2985 / -20**（`evaluation/hle.jsonl` 目前是 *modified but not staged*）

---

## 目标（对应 plan）
- **在本地（no SLURM）可复现地跑 HLE eval**：自动拉起 Orchestrator vLLM + retrieval service，再跑 eval。
- **支持混合后端路由**：Orchestrator（本地 vLLM）、专家模型（Together/Nebius/OpenAI）。
- **性能 profiling 闭环**：实验时结构化记录 wall-clock 指标，实验后用 Python 生成统计 + 分布图（含 linear/log bins）。
- **高并发可观测性**：`--concurrency` 可调，runner 输出红色 ETA，明确哪些 task 完成/是否卡住。

---

## 主要新增能力（高层总结）

- **本地一键跑**：`evaluation/run_hle_local.py` 负责起服务 + 写 config + 启 eval。
- **本地 eval 脚本**：`evaluation/eval_hle_local.py`（基于 `eval_hle.py` 的结构）支持：
  - `--concurrency` 控制任务并行度
  - Together/Nebius 路由
  - HLE profiling/结构化日志
- **结构化日志**：`evaluation/hle_logging.py` 引入 `PROFILE` / `USER_JUDGE` 两个 log level（仿 tau2-bench），并带 thread-local task 上下文（`task_id/step/eid`）。
- **离线分析 + 图**：`evaluation/analyze_hle_timing.py` 解析 `hle.log`，生成：
  - stats JSON
  - 每个指标 **10-bin 等宽直方图** + **10-bin log-scale 直方图**
- **后台全量跑 + 自动分析**：`evaluation/run_hle_profile.sh`（默认 `CONCURRENCY=512`），跑完自动调用 `analyze_hle_timing.py --bins 10`。
- **高并发 retrieval 稳定性补丁**：`evaluation/retrieval_hle.py` 对 GPU 检索关键段加全局锁，避免 FAISS GPU assertion crash。

---

## 文件级变更清单

### Modified
- **`.gitignore`**
  - **新增忽略**：`evaluation/cache/*`、`*.arrow`、`setup_envs.sh`
  - **原因**：避免 runtime artifacts 和本地密钥脚本误提交。

- **`LLM_CALL.py`**
  - **新增 Together OpenAI-compatible 调用支持**：
    - legacy/back-compat：`model="endpoint-..."`（dedicated endpoint ID）也能调用
    - `model_type in {'nv/dev','together'}` 走 Together API
  - **原因**：本地 HLE eval 需要稳定调用 Together serverless/dedicated 的 OSS expert。

- **`evaluation/retrieval_hle.py`**
  - **新增 `/health`**（给 runner 做 readiness check）
  - **启动鲁棒性增强**：若 `HF_HUB_ENABLE_HF_TRANSFER=1` 但缺 `hf_transfer`，自动降级避免启动 crash
  - **强校验 `INDEX_DIR`** 必须存在且含 `eval.index/eval.jsonl`
  - **关键修复**：加 `_RETRIEVE_LOCK` 串行化 GPU critical section，避免并发触发 FAISS GPU `StackDeviceMemory.cpp:144` assertion
  - **检索逻辑保持不变**：doc 数不足时继续 Tavily fallback。

- **`evaluation/retriever_env_setup.md`**
  - **补充 retriever env 安装/踩坑**：强调固定 `numpy<2` 防止 `faiss/scipy` ABI 冲突
  - **补充 hf_transfer crash workaround**。

- **`evaluation/tau2-bench/RUN_LOCAL_GUIDE.md`**
  - 文案小调整（无功能变化）。

### Added
- **`evaluation/run_hle_local.py`**
  - 本地 runner：起 retrieval（GPU1/1401）+ 起 orchestrator vLLM（GPU0/1406）+ 写 config + 跑 eval
  - 支持 `--concurrency`
  - 解析 `[HLE_TASK_COMPLETE]` 输出红色总体 ETA，并写入 `eval_hle_local.log`。

- **`evaluation/eval_hle_local.py`**
  - 本地 eval：路由 Orchestrator(vLLM)/Together/Nebius/OpenAI
  - profiling：每个 tool call / orchestrator vLLM 调用都落 `PROFILE` 结构化日志
  - 健壮性：任务失败也会打出 `[HLE_TASK_COMPLETE] status=error ...`，保证 runner ETA 不会“卡死不动”。

- **`evaluation/hle_logging.py`**
  - tau2 风格结构化 logging：`PROFILE`/`USER_JUDGE`，task context（`task_id/step/eid`），`Timer`，`log_profile_event()` 等。

- **`evaluation/analyze_hle_timing.py`**
  - 离线解析 `hle.log`，输出 stats JSON + linear/log 两套直方图 PNG（10 bins）。

- **`evaluation/run_hle_profile.sh`**
  - 后台启动 full run（默认 `CONCURRENCY=512`）+ 定期写 `monitor.out` + 结束后自动跑分析脚本。

- **`evaluation/check_hle_duplicate_ids.py`**
  - 检查 HLE jsonl 是否有重复 `id`。

- **`evaluation/hle_20.jsonl`**
  - 20-task smoke 子集（包含 benchmark canary，勿用于训练语料）。

- **`evaluation/model_configs/hle_local.json`**
  - 本地 config 样例（retrieval `127.0.0.1:1401`，orchestrator `127.0.0.1:1406`）。

- **`test_together_endpoint_math.py`**
  - Together dedicated endpoint “Name string” 的调用 sanity test。

- **`START_LOCAL.md`**
  - 本地 quickstart 笔记（已去除任何真实 token，全部用占位符）。

---

## Profiling 指标（落日志、跑后分析出图）
- **tool call wall-clock（分布）**
  - `enhance_reasoning`（含 code execution）
  - `search`（含 retrieval/web search）
  - `answer`（专家模型；同时在日志里可区分 `duration_ms` vs `duration_total_ms`/`judge_ms`）
  - 以及 **all tools combined**
- **Orchestrator vLLM 指标（每次调用）**
  - **prefill**：latency + prompt tokens
  - **decode**：latency + completion tokens
  - **infer（prefill+decode）**：latency
  - **total length**：prompt+completion tokens
- **可视化**：每个指标都生成
  - **10-bin 等宽（linear）直方图**
  - **10-bin log-scale（log-spaced bins）直方图**

---

## 今天遇到的问题 & 可能的解决方案

### 1) 高并发打爆 retrieval：FAISS GPU assertion
- **报错**：`Faiss assertion 'p + size == head_' failed ... StackDeviceMemory.cpp:144`
- **根因**：
  - FastAPI sync endpoint 在 threadpool 内并发执行；
  - 多线程同时调用共享的 FAISS GPU index + 共享 embedding model；
  - FAISS GPU `GpuResources/stack allocator` 并非线程安全。
- **已实现的最简单 fix（稳定优先）**：
  - `evaluation/retrieval_hle.py` 在 `encode + index.search` critical section 外层加全局锁（串行化）。
- **更优（吞吐更好）的方案：micro-batching（服务端）**
  - **客户端不改**：仍保持“一条 query 一个请求”
  - **服务端内部做队列**：按 `max_batch_size/timeout_ms` 合并请求，一次 `encode(batch)+search(batch)`，再拆分返回。
  - **参数建议**：`timeout_ms=10~50ms` 常见起点；`0.5s` 可能显著抬高 tail latency（吞吐↑但 P95/P99 可能恶化）。

### 2) API keys 没注入导致“没有完成任务/没有 ETA”
- **现象**：expert 调用失败，任务没完成，runner 看起来像卡住。
- **缓解**：
  - eval 即使失败也打印 `[HLE_TASK_COMPLETE] status=error ...`，保证 ETA 会推进；
  - 强烈建议跑 eval 前 `source setup_envs.sh`（但该文件已被 `.gitignore` 忽略，避免泄漏）。

### 3) `HF_HUB_ENABLE_HF_TRANSFER=1` 但缺 `hf_transfer` 导致启动崩溃
- **现象**：HuggingFace 下载直接抛错。
- **缓解**：
  - retrieval/eval 自动把 `HF_HUB_ENABLE_HF_TRANSFER` 降级为 0（并打印 warning）
  - 或手动安装 `hf_transfer`。

### 4) retriever env 的 `numpy/scipy/faiss` ABI 冲突
- **现象**：pip 把 numpy 升到 2.x 后，faiss/scipy 出 ABI mismatch。
- **缓解**：`evaluation/retriever_env_setup.md` 给出卸载 pip numpy 并用 conda-forge 固定 `numpy<2` 的修复流程。

---

## “NV 原来在 slurm 上怎么跑，为什么不冲突？”
- **结论**：原版 `evaluation/eval_hle.py` 的 task-level 并发是 **默认=2**，且入口没有 CLI 参数覆盖（直接 `run_all(examples)` 用默认值）。并发太低，基本不会把 FAISS GPU 的线程不安全问题打出来。
- **`evaluation/run_hle.py`** 的 SLURM serve 脚本里：
  - `SERVE_REPEAT = 1`
  - **只起一个** retrieval server（`retrieval_hle.py --port 1401`），并不是“两个 retrieval service”来隔离冲突。
- **所以**：避免 conflict 的关键不是 “多部署几个 retrieval server”，而是 **并发非常低**（+服务可能跑在独占节点上）。

---

## Commit 前检查建议
- **确认不提交 secrets**：
  - `setup_envs.sh` 已被 `.gitignore` 忽略（应保持 untracked）
  - `START_LOCAL.md` 已用占位符替换 token
- **确认不提交数据集**：
  - `evaluation/hle.jsonl` 当前未 staged（建议保持不提交；必要时用 `--example-path` 指向真实数据路径）


