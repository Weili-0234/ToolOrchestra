# Work Log — OSS expert model eval (HLE / FRAMES)
**Date**: 2025-12-30  
**Scope**: HLE+FRAMES OSS experts evaluation reliability (retrieval, logging/latency, resume), plus Slurm/tmux bookkeeping.

---

## 1) 基于哪些交接文档推进

- **`evaluation/HANDOVER_OSS_EVAL.md`**  
  - 重点跟进：  
    - “重要遗漏问题”里的 **Retrieval service 未启动**（导致 search tool 无限等待）。  
    - **PROFILE log level** 低于 INFO 被过滤（导致 latency 缺失）。  
    - “Tool-Specific Latency Components” 需要把 tool latency 拆到可分析字段。
- **`evaluation/PLAN_HLE_FRAMES_OSS.md`**  
  - 重点跟进：Quick Start 的 **node allocation + model_config 更新 + tmux 启动** 流程，并把 “Monitoring / Cleanup” 的操作落成可复用脚本/日志习惯。
- **`tmux-nodes.md`**  
  - 按用户要求：只记录 `junxiong` 在 ToolOrchestra eval（HLE/FRAMES/tau2）实际占用的 tmux/Slurm 节点；明确 **`run-0/run-1` (research-secure-01/03) 为共享不可动**。

---

## 2) 新增/修改了什么代码（高信号清单）

### 2.1 评估脚本：防卡死 + 可恢复

- **`evaluation/eval_hle_oss.py`**
  - **修复 import**：保证能找到 `LLM_CALL`（避免 `ModuleNotFoundError`）。
  - **检索请求加护栏**：对 retrieval 的 `requests.post()` 增加 **timeout + max_attempts + exponential backoff**，并在 retriever down 时 **不中断整场评估**（继续用 empty results）。
  - **参数化 Orchestrator 输出长度**：新增 `--orch_max_tokens`，用于处理长输出/难例。
  - **latency 字段完善**：search tool PROFILE 记录包含 `query_llm_ms / retrieval_ms / retrieval_retries / search_backend` 等。

- **`evaluation/eval_frames_oss.py`**
  - 同步 HLE 的策略：对 retrieval 增加 **timeout/retry/backoff**；并支持 **优先 wiki_retrieval，失败时 fallback 到通用 retrieval**。

### 2.2 Retrieval 服务：更稳的启动与兼容性

- **`evaluation/oss_scripts/launch_retrieval.sh`**
  - 新增一个“可直接 srun/sbatch 使用”的 launcher：激活 `retriever` env、检查 index 文件、启动 `retrieval_hle.py`，可选启动 `retrieval_wiki.py`。

- **`evaluation/retrieval_hle.py`**
  - **FlashAttention2 兼容**：当环境缺 `flash_attn` 时，自动从 `flash_attention_2` 降级到 `sdpa/eager`，避免服务直接起不来。

- **`evaluation/retrieval_wiki.py`**
  - **FlashAttention2 兼容**：同上。
  - **Wiki index OOM 规避**：默认 **不把 FAISS index 放 GPU**（用 `WIKI_FAISS_GPU=1` 才启用 GPU），避免单卡 OOM。

### 2.3 配置与运维脚本

- **`evaluation/model_config_oss_hle.json`**
  - 更新 endpoints：
    - `retrieval` → `research-secure-13:8765`
    - `wiki_retrieval` → `research-secure-14:8766`

- **`evaluation/oss_scripts/run_hle_missing9.sh`**
  - 新增：用于 **sbatch** 跑 `hle_missing_9.jsonl` 的脚本（非交互式更稳）。
  - 处理 Slurm 非交互环境细节：
    - `setup_envs.sh` 可能引用未定义变量 → 临时关闭 `set -u` 再 source。
    - 用 `conda run --no-capture-output ... python -u`，避免 Slurm 日志看起来“卡住”。

---

## 3) 做了什么实验 / 跑了什么作业（含日志定位）

### 3.1 Retrieval services（解 search hang 的核心前置）

- **HLE retrieval**：Slurm job **13397**（node `research-secure-13`, port 8765）  
  - 相关日志：`evaluation/oss_scripts/logs/slurm_retrieval_hle_13397.*`, `evaluation/oss_scripts/logs/retrieval_hle_port8765_20251229.log`
- **Wiki retrieval**：Slurm job **13406**（node `research-secure-14`, port 8766）  
  - 相关日志：`evaluation/oss_scripts/logs/slurm_wiki_retrieval_13406.*`, `evaluation/oss_scripts/logs/retrieval_wiki_port8766_20251229.log`

### 3.2 HLE full + resume（定位“跑着跑着就不动/进程消失”）

- Full run 日志（关键几个）：
  - `evaluation/logs_oss/hle_full_20251229_143301.log`
  - `evaluation/logs_oss/hle_full_20251229_155254.log`（已开启 `--log_level PROFILE`，有 tool latency）
- 当 full run 中途退出后：
  - 生成并跑 **missing 24**：`evaluation/logs_oss/hle_resume_missing_20251229_180310.log`
  - 再聚焦剩余 hard cases **missing 9**：
    - `evaluation/logs_oss/hle_resume_missing9_conc1_20251229_190522.log`（conc=1, orch_max_tokens=12000）

### 3.3 Slurm 批处理稳定性实验（为了解决“看起来卡死但其实日志被吞/脚本没跑起来”）

- job **13416**：失败原因 `/bin/sh` 不支持 `source`（err: `source: not found`）  
- job **13417**：失败原因 `--wrap` 引号嵌套错误（err: `Unterminated quoted string`）  
- job **13425**：脚本启动但 Slurm out 不刷新（根因：`conda run` 默认 capture 输出）→ 已在 `run_hle_missing9.sh` 修复为 `--no-capture-output` + `python -u`  

---

## 4) 解决了什么 bug（按影响排序）

- **Bug: search tool 会无限等待（retrieval service 未启动）**  
  - 解决：上线 `retrieval_hle` 服务 + 更新 `model_config_oss_hle.json`；并在 eval 侧增加 timeout/retry，防止“服务挂了整场 eval 也挂住”。

- **Bug: latency 日志缺失（PROFILE level 被过滤）**  
  - 解决：评估启动统一使用 `--log_level PROFILE`，并确保关键 tool fields 写入 PROFILE 行。

- **Bug: `ModuleNotFoundError: No module named 'LLM_CALL'`**  
  - 解决：在 eval 脚本里保证 REPO_PATH 可导入（避免环境差异导致 import 失败）。

- **Bug: FlashAttention2 依赖缺失导致 retriever 启动失败**  
  - 解决：`retrieval_hle.py` / `retrieval_wiki.py` 自动降级到 SDPA/eager。

- **Bug: wiki retrieval GPU OOM**  
  - 解决：默认 `faiss_gpu=False`（只在显式设置 `WIKI_FAISS_GPU=1` 时上 GPU）。

- **Bug: retrieval 网络/服务异常导致 requests 永久卡住**  
  - 解决：在 `eval_hle_oss.py` / `eval_frames_oss.py` 的 retrieval call 增加 `(connect_timeout, read_timeout)` + retry/backoff。

---

## 5) 新遇到但暂未完全解决的问题

### 5.1 HLE driver 进程“消失/提前退出”且日志不总是给出 stacktrace

- 现象：full/resume 运行到某个点后，`eval_hle_oss.py` 进程不在了，但输出未 complete。  
- 推测：可能是外部中断/资源问题/或某些请求触发长时间阻塞导致被系统回收；需要把 run 固化到 sbatch 并保留完整 stdout/stderr + exit code 才能稳定定位。

### 5.2 remaining hard cases 仍未清零（当前剩余 3 个）

- 当前 `outputs_oss_hle_full/` 对比 `hle.jsonl` 的缺失 id 仍有 3 个：
  - `6724a01ff14c6dca507d5e18`
  - `66fec7825e6051260840e060`
  - `672ec55453f431bf8d3dc928`
- 需要下一步把这 3 个单独拆出来（`hle_missing_3.jsonl`）逐个跑，并把每个 task 的最后一次 vLLM 调用/返回状态记录下来，判断是：
  - Orchestrator 输出过长（token/timeout）
  - 某个 expert endpoint 偶发错误
  - 或评估脚本自身异常退出

### 5.3 vLLM 请求策略仍偏“无限重试”

- `LLM_CALL.py` 对 vLLM 有固定 `timeout=600s`，但整体是 `while answer == ''` 的重试模式（无 max retries），在某些异常情况下可能导致长时间拖住/难以 fail-fast。  
- 后续建议：把 vLLM timeout/max_retries/backoff 也做成 env/args 可配，并在达到阈值后让 task 明确失败并落盘（便于 resume）。

---

## 6) 明日/下一步行动（按优先级）

1. 生成 `hle_missing_3.jsonl`，用 **sbatch + conc=1** 逐个完成/定位失败原因，目标把 HLE full 补齐到 1900/1900。  
2. 给 `LLM_CALL.py` 增加 **可配置的 vLLM timeout + max_retries**（避免“无上限重试”吞时间）。  
3. 启动/恢复 **FRAMES full**，并跑 latency 分析（按 enhance_reasoning/search/answer 输出 10-bin hist）。  


