# Ï„Â²-Bench æœ¬åœ°è¿è¡Œå¿«é€Ÿå¼€å§‹

5 åˆ†é’Ÿå¿«é€Ÿå¯åŠ¨æŒ‡å— ğŸš€

## æ­¥éª¤ 1ï¸âƒ£: å®‰è£… Conda ç¯å¢ƒ

```bash
# åˆ›å»º vllm1 ç¯å¢ƒ
conda create -n vllm1 python=3.12 -y
conda activate vllm1

# å®‰è£…ä¾èµ–
pip install torch
pip install "transformers<4.54.0"
pip install vllm==0.9.2

# å®‰è£… tau2-bench
cd evaluation/tau2-bench
pip install -e .
```

## æ­¥éª¤ 2ï¸âƒ£: é…ç½®ç¯å¢ƒå˜é‡

ç¼–è¾‘ `setup_envs.sh`ï¼Œè®¾ç½®ä»¥ä¸‹å…³é”®å˜é‡ï¼š

```bash
# 1. è®¾ç½®æ¨¡å‹è·¯å¾„
export CKPT_DIR="/path/to/your/Orchestrator-8B"

# 2. è®¾ç½® OpenAI API Key (ç”¨äº user simulation)
export OPENAI_API_KEY="sk-..."

# 3. è®¾ç½® Nebius API Key (ç”¨äº Qwen3-32Bï¼Œé¿å…æœ¬åœ°éƒ¨ç½²)
export NEBIUS_API_KEY="v1...."

# 4. (å¯é€‰) å…¶ä»– API keys
export ANTHROPIC_API_KEY="sk-ant-..."
```

ç„¶ååŠ è½½ç¯å¢ƒå˜é‡ï¼š

```bash
cd /path/to/ToolOrchestra
source setup_envs.sh
```

**ğŸ’¡ å…³äº Nebius API**: å¦‚æœè®¾ç½®äº† `NEBIUS_API_KEY`ï¼ŒQwen3-32B (expert-3) ä¼šè‡ªåŠ¨é€šè¿‡ Nebius API è°ƒç”¨ï¼Œæ— éœ€åœ¨æœ¬åœ°å¯åŠ¨ Qwen3-32B çš„ vLLM æœåŠ¡å™¨ã€‚è¯¦è§ [NEBIUS_INTEGRATION.md](../../NEBIUS_INTEGRATION.md)ã€‚

## æ­¥éª¤ 3ï¸âƒ£: ä¸‹è½½æ¨¡å‹

```bash
# ä¸‹è½½ Orchestrator-8B æ¨¡å‹
git clone https://huggingface.co/nvidia/Nemotron-Orchestrator-8B $CKPT_DIR
```

## æ­¥éª¤ 4ï¸âƒ£: è¿è¡Œè¯„æµ‹

```bash
cd evaluation/tau2-bench/
python run_local.py --agent-model $CKPT_DIR
```

**å°±è¿™ä¹ˆç®€å•ï¼** ğŸ‰

---

## å¸¸è§åœºæ™¯

### åœºæ™¯ 1: åªæœ‰ 1 ä¸ª GPU

```bash
python run_local.py \
  --agent-model $CKPT_DIR \
  --num-servers 1 \
  --domains retail  # å…ˆæµ‹ä¸€ä¸ªåŸŸ
```

### åœºæ™¯ 2: æœ‰ 4+ ä¸ª GPU

```bash
python run_local.py \
  --agent-model $CKPT_DIR \
  --num-servers 4 \
  --domains retail telecom airline  # æµ‹æ‰€æœ‰åŸŸ
```

### åœºæ™¯ 3: å¿«é€Ÿæµ‹è¯•ï¼ˆåªè·‘å°‘é‡æ ·æœ¬ï¼‰

```bash
# ä¿®æ”¹ task file æˆ–ä½¿ç”¨ --num-trials å‚æ•°
python run_local.py \
  --agent-model $CKPT_DIR \
  --domains retail \
  --num-trials 1 \
  --max-steps 50
```

---

## æ£€æŸ¥æ¸…å• âœ…

è¿è¡Œå‰ç¡®ä¿ï¼š

- [ ] âœ… Conda ç¯å¢ƒ `vllm1` å·²æ¿€æ´»
- [ ] âœ… `CKPT_DIR` å·²è®¾ç½®ä¸”æ¨¡å‹å·²ä¸‹è½½
- [ ] âœ… `OPENAI_API_KEY` å·²è®¾ç½®
- [ ] âœ… `NEBIUS_API_KEY` å·²è®¾ç½®ï¼ˆæ¨èï¼Œç”¨äº Qwen3-32Bï¼‰
- [ ] âœ… `REPO_PATH` å·²è®¾ç½®ï¼ˆæˆ–åœ¨ä»“åº“æ ¹ç›®å½•è¿è¡Œï¼‰
- [ ] âœ… è‡³å°‘æœ‰ 1 ä¸ªå¯ç”¨ GPU

éªŒè¯å‘½ä»¤ï¼š
```bash
# æ£€æŸ¥ GPU
nvidia-smi

# æ£€æŸ¥ç¯å¢ƒå˜é‡
echo $CKPT_DIR
echo $OPENAI_API_KEY
echo $REPO_PATH

# æ£€æŸ¥ conda ç¯å¢ƒ
conda info --envs | grep vllm1
```

---

## é¢„æœŸè¾“å‡º

è¿è¡ŒæˆåŠŸåï¼Œä½ ä¼šçœ‹åˆ°ï¼š

```
[2025-12-23 10:00:00] Starting 4 vLLM server(s)...
[2025-12-23 10:00:00] Starting vLLM server: /path/to/model
[2025-12-23 10:00:00]   GPU: 0, Port: 1900
[2025-12-23 10:01:00] Starting vLLM server: /path/to/model
[2025-12-23 10:01:00]   GPU: 1, Port: 1901
...
[2025-12-23 10:15:00] âœ“ Server on port 1900 is ready (took 300s)
[2025-12-23 10:15:00] âœ“ Server on port 1901 is ready (took 240s)
...
[2025-12-23 10:15:30] Model configuration written to model_config_local.json
[2025-12-23 10:15:30] ========== Starting evaluation: RETAIL ==========
...
[2025-12-23 12:00:00] ========== Finished RETAIL evaluation successfully ==========
...
============================================================
EVALUATION SUMMARY
============================================================
RETAIL: SUCCESS
TELECOM: SUCCESS
AIRLINE: SUCCESS
============================================================
```

ç»“æœä¿å­˜åœ¨ï¼š
- `outputs/retail.json`
- `outputs/telecom.json`
- `outputs/airline.json`

---

## æ•…éšœæ’æŸ¥

### é—®é¢˜: "CUDA out of memory"

**è§£å†³**: å‡å°‘æœåŠ¡å™¨æ•°é‡
```bash
python run_local.py --agent-model $CKPT_DIR --num-servers 1
```

### é—®é¢˜: "Server failed to start"

**è§£å†³**: æ£€æŸ¥æ—¥å¿—
```bash
cat logs/vllm_port_1900_*.err
```

### é—®é¢˜: "OPENAI_API_KEY not found"

**è§£å†³**: è®¾ç½®ç¯å¢ƒå˜é‡
```bash
export OPENAI_API_KEY="sk-..."
source setup_envs.sh
```

---

## ä¸‹ä¸€æ­¥

- ğŸ“– è¯¦ç»†æ–‡æ¡£: æŸ¥çœ‹ [RUN_LOCAL_GUIDE.md](RUN_LOCAL_GUIDE.md)
- ğŸ”§ è‡ªå®šä¹‰é…ç½®: `python run_local.py --help`
- ğŸ“Š åˆ†æç»“æœ: æŸ¥çœ‹ `outputs/*.json` æ–‡ä»¶

---

## è·å–å¸®åŠ©

```bash
# æŸ¥çœ‹æ‰€æœ‰é€‰é¡¹
python run_local.py --help

# æµ‹è¯•ç¯å¢ƒè®¾ç½®
source setup_envs.sh

# æ£€æŸ¥ä¾èµ–
pip list | grep -E "vllm|transformers|torch"
```

ç¥è¯„æµ‹é¡ºåˆ©ï¼ğŸ¯
